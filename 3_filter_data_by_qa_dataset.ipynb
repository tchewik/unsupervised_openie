{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load simpleQA dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ../uopenie_qa/SimpleWikidataQuestions/csv\\ decoded/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in [\n",
    "#     \"../uopenie_qa/SimpleWikidataQuestions/csv decoded/annotated_wd_data_test_answerable_decoded.csv\",\n",
    "#     \"../uopenie_qa/SimpleWikidataQuestions/csv decoded/annotated_wd_data_train_answerable_decoded.csv\",\n",
    "    \"../uopenie_qa/SimpleWikidataQuestions/csv decoded/annotated_wd_data_valid_answerable_decoded.csv\",\n",
    "]:\n",
    "    data.append(pd.read_csv(file))\n",
    "    \n",
    "data = pd.concat(data)    \n",
    "data.subject_decoded = data.subject_decoded.map(lambda row: row.strip())\n",
    "data.object_decoded = data.object_decoded.map(lambda row: row.strip())\n",
    "data.property_decoded = data.property_decoded.map(lambda row: row.strip())\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {}\n",
    "\n",
    "for idx in data.index:\n",
    "    if not mapper.get(data.iloc[idx]['property_decoded']):\n",
    "        mapper[data.iloc[idx]['property_decoded']] = data.iloc[idx]['mapped_rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use for mapper initialization on test data\n",
    "\n",
    "# mapper = {}\n",
    "\n",
    "# for property in data.property_decoded.unique():\n",
    "#     print(property, flush=True)\n",
    "#     mapper[property] = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mapped_rel'] = data.property_decoded.map(lambda row: mapper.get(row) or row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../uopenie_qa/SimpleWikidataQuestions/csv decoded/annotated_wd_data_valid_answerable_decoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "trex_path = 'trex_data'\n",
    "aligned_trex_path = 'trex_simpleqa_aligned'\n",
    "\n",
    "! mkdir $aligned_trex_path \n",
    "\n",
    "#clean_dataset = {}  #pickle.load(open(f'{aligned_trex_path}.pkl', 'rb'))\n",
    "counter = 0\n",
    "\n",
    "for dataset_file in tqdm(glob.glob(os.path.join(trex_path, '*.json'))[139:156]):\n",
    "    dataset = pd.read_json(dataset_file)\n",
    "    clean_rows = []\n",
    "    \n",
    "    for document in tqdm(range(dataset.shape[0])):\n",
    "#     for document in tqdm(range(100)):\n",
    "        entity = dataset.iloc[document].docid.split('/')[-1]\n",
    "        for arguments in data[['subject_encoded', 'object_encoded']].values:\n",
    "            if entity in arguments:\n",
    "                clean_rows.append(document)\n",
    "                break\n",
    "                \n",
    "    clean_dataset[dataset_file] = clean_rows\n",
    "    counter += 1\n",
    "    \n",
    "    if counter == 5:\n",
    "        pickle.dump(clean_dataset, open(f'{aligned_trex_path}.pkl', 'wb'))\n",
    "        counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clean_dataset, open(f'{aligned_trex_path}.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
